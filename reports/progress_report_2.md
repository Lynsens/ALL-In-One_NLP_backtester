# CSDS 395 - Report 2: An All-In-One NLP Stock Market Backtester

> Shaochen (Henry) ZHONG `sxz517`
> Jiaqi Yu `jxy618`
> Mocun Ye `mxy293`

---
*Due and submitted on 11/06/2020*

---


## Background

The background of the project remains largely unchanged from our perviously submitted proposal and report. So here we will provide a concentrated version of it.

Using NLP related approaches to do some kinds of prediction on stock market is nothing new among traders who want to develop profitable trading strategies, researchers who want to testify their models' performances, and also to every developer who wants to have some hand-on ML/DL experience.

Despite the popularity, we noticed that it is rather hard to verify a NLP-stock-prediction model's performance since the researcher will have to gather the plain text data, gather the company data, gather the stock market data, and categorize them in a way that is communicable with each other and the model; then the researcher will need to build a virtual trading platform that keeps track of all the trading signals generated by the model, and visualize them for evaluation.

To implement all these steps from ground up, it is required for a researcher to have certain level of proficiency on skills which are, from a research stand-point, fairly deviated from the nature of the NLP model itself (like scraping a website and understanding the fundamental mechanism of trading in stock market). Even though there are some very mature tools being developed in the subareas of this task (especially on the stock market backtesting area), it still requires a reasonably large amount of effort to couple them together, and to store necessary information in a way that are not only communicable with each other, but also suits to the design of each and every tool a research chose to use. It is our understanding this kind of preliminary work will distract a researcher from the essence of his/her work -- developing an SOTA model, and will also create a unnecessary barriers for researcher who wants to quickly testify an idea in a controlled manner, or to who are in the need of reproducing a published work.


We like to build a set of tools that may automate such process to a certain degree. The ideal workflow we visioned is that developers may import their plain text and company data in a certain format (or even use the build-in API to obtain such data, of course, with limitation on available channels), then we will have a set of functions (or parsers) available to execute and register the trading signals generated by a desired model; our toolkit will also able research to restructure data in a way that is suitable for his/her model. In our pervious proposal we said if time’s available, we may even built in some classic NLP model just to provide a benchmark reference on “the same playing field,” or develop my own HMM model I am researching right now for demo. **In our [pervious report](https://github.com/choH/ALO_NLP_backtester/blob/master/reports/progress_report_1.md), by re-evaluating of our team members' course load per TA's feedback, we have dropped the idea of actually providing a technically significant model, but just to place a "dummy model" to demonstrate our project's capability.**

In our pervious proposal, we also researched couple related works regarding this task (mostly focusing on the fields of backtesting, obtaining stock market data, and obtaining plain text data). We analyzed the pros-and-cons of several existing public available libraries and described why are (or why aren't) we developing own our tools, and what functionalities were expected. Please do review our [*Proposal*](https://github.com/choH/ALO_NLP_backtester/blob/master/reports/proposal.md) if you'd expect more information regarding related works.


---


---

## Progress Report

Per our last report, by the time this report is written, we should be working on:

* Week of 11/02/2020:
    * Visualizer development (if needed).
    * Test and debug coupling everything.
    * Report 2 writing.

So in short, we want to finish the majority of development among plain text data provider and virtual trading platform, couple the two together, and start on developing Visualizer if possible.

As an overview, we are around 1 week late in comparison to our desired plan. We have done the development of text data provider (we named it `text_obtainer` in terms of folder structure), and are probably around 85% done for the virtual trading platform. We are trying to couple them together but not fully done, and we haven't progress much on visualizer except some testing and learning. So we are more on the mark of a week ago:

* Week of 10/26/2020:
    * Test and debug coupling between virtual trading platform and plain text data provider.
    * Visualizer development with respect to trade log.
    * Data organizer development with respect to achievement of  virtual trading platform.


The reason of this delay are mainly two-fold: one if the midterm, the plan we have for the midterm weeks is like:

* Week of 10/12/2020:
    * Refactor scraper.
    * Virtual trading platform development / Regulate trade log format.
    * Design visualizer.

* Week of 10/19/2020:
    * Finish plain text data provider development.
    * Visualizer development with respect to trade log.
    * Data organizer design.

But with various midterm dates among different group members, we can hardly unify our time to design a trade log. The second is there is a structure change among WSJ webpage around the time of `2012`, thus we have to therefore develop an alternative scraper to support the alternative structure, and integrate this into our program workflow -- which is rather complicated.

However, we have done our solo work rather nicely. We are particularly proud in terms of the workflow and folder structure we designed and implemented (details in the following section).

### Regarding Text Input


#### Demo of Achievement
It took some registrations (`WSJ` and `Scale SERP` for the start) to get the `text_obtainer` module running, and some of them cost money. So here's a GIF of how it will look like when executed. We choose [WSJ News Archive for January 2](https://www.wsj.com/news/archive/2012/01/02) to be the demo day, although it can technically obtain data from any day or duration of days as long as the page structure is supported:


![text_obtainer_demo_720p](https://github.com/choH/ALO_NLP_backtester/blob/master/reports/pic/text_obtainer_demo_720p.gif)

Note this is just the log of the executed task, each article will be stored in the format of:

```
{
    "channel": "WSJ",
    "date": "20120102",
    "url": "https://www.wsj.com/articles/SB10001424052970203462304577134772333692402",
    "author": "Danny Yadron",
    "headline": "Jabs Fly as Iowa Caucuses Near",
    "quotes": [],
    "content": "MARSHALLTOWN, IOWA -- Former House Speaker Newt Gingrich signaled here Sunday that he plans to take a much more confrontational approach against GOP presidential front-runner Mitt Romney as the nominating race moves from Iowa to New Hampshire. \nThe change suggests that Mr. Gingrich feels less threatened by former Sen. Rick Santorum, who has recently surged in Iowa polls, than by the barrage of negative ads that have aired in Iowa...",
    "article_id": "d26a648d-fd8e-4ab6-8de0-37e38f98322a"
}
```
And a `company_market_LUT` like:

```
{
    "Leap Wireless International": {
        "market_data_url": "https://www.wsj.com/market-data/quotes/LEAP.UT",
        "ticker": "LEAP.UT",
        "exchange": "U.S.: NYSE",
        "legal_full_name": "Ribbit LEAP Ltd. Un",
        "quoted_in": [
            "6d2cb1fa-a88a-407a-a71d-1c3ca7407447"
        ]
    },
    "Bayer": {
        "market_data_url": "https://www.wsj.com/market-data/quotes/BAYRY",
        "ticker": "BAYRY",
        "exchange": "U.S.: OTC",
        "legal_full_name": "Bayer AG ADR",
        "quoted_in": [
            "090faba5-1f06-462f-b685-16e1f8e95768"
        ]
    },
    "BASF": {
        "market_data_url": "https://www.wsj.com/market-data/quotes/BASFY",
        "ticker": "BASFY",
        "exchange": "U.S.: OTC",
        "legal_full_name": "BASF SE ADR",
        "quoted_in": [
            "090faba5-1f06-462f-b685-16e1f8e95768"
        ]
    },
    ...
}
```

#### Folder Structure
![text_obtainer_folder_structure](https://github.com/choH/ALO_NLP_backtester/blob/master/reports/pic/text_obtainer_folder_structure.png)

The [text_obtainer](https://github.com/choH/ALO_NLP_backtester/tree/master/text_obtainer) folder is where everything starts. It first contains a [`logger.py`](https://github.com/choH/ALO_NLP_backtester/blob/master/text_obtainer/logger.py) to store the log of the task in its output.


Then, in its subfolder [channel](https://github.com/choH/ALO_NLP_backtester/tree/master/text_obtainer/channel), we have listed all supported publishers. In this case, we have [WSJ](https://github.com/choH/ALO_NLP_backtester/tree/master/text_obtainer/channel/WSJ) implemented to be the demo.

The [WSJ/src](https://github.com/choH/ALO_NLP_backtester/tree/master/text_obtainer/channel/WSJ/src) contains many modules to support obtaining data from such publisher. These modules may vary depending on the publisher you desired, as each publisher may organize their interface in very different ways. But the common thing is simple, you setup your [`setting.json`](https://github.com/choH/ALO_NLP_backtester/blob/master/text_obtainer/channel/WSJ/setting.json) with required account credentials and essential informations (start/end date, output directory, etc), and you are good to go with:

```
ALO_NLP_backtester $ python3 text_obtainer/channel/WSJ/src/main.py
```

The outputs will be stored in the *text_obtainer_output* folder. This folder is set to not sync with GitHub on purpose as there can be thousands of files under it (and also for copyright concerns). In short, you may find out the plain text data of smallest unit objects (in this case, it is an article) under the *text_obtainer_output/articles* folder. The log and metadata of the text are stored in *text_obtainer_output/logs* and *text_obtainer_output/market_data* accordingly.

#### Workflow

![text_obtainer_workflow](https://github.com/choH/ALO_NLP_backtester/blob/master/reports/pic/text_obtainer_workflow.png)


#### Scalability and Implementation Details

We have implemented some unique identifier as an overlay of company and articles, so the general structure can be universally used across different publishers — should the `text_obtainer` of another channel will be implemented. This will facilitate the process of coupling with the virtual trading platform. However, we noticed this layer will only helps us ID which company is mentioned in which article, we can't do something like "filter articles with more than 500 words" without iterating through all articles. This will be something critical as some models may not take an article as input due to some property of the article (like the abovementioned length), even though such article is obtainable (and it is already obtained) by our program.

To overcome this, We plan to have something like [`unit_schema.json`](https://github.com/choH/ALO_NLP_backtester/blob/master/text_obtainer/channel/WSJ/scheme/unit_schema.json) to check the validity before the program stores each smallest unit object (an article in the WSJ case). So by editing the JSON schema, the user may implant some limiters onto our program when obtaining textual data from certain publishers.


### Regarding Trading

#### Recap from progress report 1:

In the previous report, we finished the basic design of the backtesting platform, following the principle of being simple while scalable. To run a model on this backtesting platform involves three phases, configuration, data fetching, and emulation.

In the first configuration phase, the user initialize an instance of the backtesting module, configures the features according to the model, including the time frame, the reporting features, and the callback function from the model that would be used when the emulation starts.

Then, in the second data fetching phase, which is also optional, the user may import data by batch for the model to be trained offline. The data provided in this step is also complied to the configurations above. This step is optional, depending on whether the model is partially trained offline or completely online.

Finally, finishing all the configuration, the user may start the emulation, and the platform would run the model on the selected time frames.

#### Design Update:

We have refined our design in several aspects, making it provides a more comprehensive feature set as well as an easier interface.

First of all, we designed an interface, involving several "get" functions, for the user to fetch the result after the emulation finished. We originally expected that the user may easily keep the statics within their model. However, since we wanted our user to focus simply on their model, leaving all the backtesting related codes to our platform, we decided to add the statistic features, which keeps track of several simple statics about trading, allowing users to analysis or even plot the trading history easily.

We provides the following data in our statics. Note that despite that some of these statistics are available within the `backtesting` module of python, we actually re-implemented most of them. This is due to that the statistics provided in `backtesting` only applies to the fixed time frame, and could be wrong when we emulate the trades on different time frames and with the market events.

| Data | Description |
| ---- | ----------- |
|`Start Time`| The beginning timestamp of the emulation. Returned in human-friendly format. |
|`End Time`| The ending timestamp of the emulation. Returned in human-friendly format. |
|`Total Frame Count`| The total time frame count. Equivalent to the total time of the callback function being called, or the time the iteration function being called in the active emulation mode. |
|`Total Event Count`| The total number of market event occurred during the emulation. |
|`Exposure Time`| The weighted average time of the capital being invested in the market. |
|`Initial Capital`| The owned capital size before the emulation started. |
|`Final Capital`| The owned capital size after the emulation ended. |
|`Maximum Capital`| The maximum capital the model ever reached during the emulation. |
|`Minimum Capital`| The minimum capital the model ever reached during the emulation. |
|`Return`| The overall return. Equivalent to the Final Capital divided by the Initial Capital. |
|`Total Trade Count`| The total number of trades initiated by the model. |
|`Winning Trade`| The percentage of all the trades that have a positive return comparing to the last trade. |
|`Best Trade`| The highest return of a single trade ever during the emulation. |
|`Worst Trade`| The lowest (usually negative) return of a single trade ever during the emulation. |
|`Average Trade`| The average trade return through the emulation. |
|`Expectancy`| The probabilistic expectation of the trade return. Calculated from the winning/losing rate and the average winning/losing size. |
|`Trade List`| The  |

Besides, after further investigation, we found that for the average researcher, it could be hard if we only allow the model to be run with a callback function - it is actually counter-intuitive to write a responsive program module, and could be a challenge for the model designer. It could be much easier for the users if we allow the users to actively request for the new time frame, and we make our backtesting platform responsive. This is also a feature that most of the backtesting system lack of.

To allow the users program their model in an active scheme, we provide the following new functions as a complement to the original third phase:

| Function | Parameters | Description |
|--------|------|-------|
|`.emulate_init()`| None | Initialize the emulation related variables. Basically the same work as the initialization done with in the `run()` function. |
|`.emulate_iterate()`| None | Proceed to the next time frame. Updates the data to the next time frame within the platform.</br>Returns a tuple of the exact same variables that would have been passed to the callback function. Returns an empty tuple that would evaluate to `False` when we reach the ending timestamp and the emulation is finished. |

#### Current Progress:

Phase 1:

| Functions/Features | Progress |
|--------------------|----------|
| public configuration variables | Done. |
| initialization | To be implemented. |
| `set_init_callback()` | Done. |
| `set_iterate_callback()` | Done. |

Phase 2:

| Functions/Features | Progress |
|--------------------|----------|
| public configuration variables | Done. |
| `prefetch_data()` | Work in progress. |

Phase 3:

| Functions/Features | Progress |
|--------------------|----------|
| callback market events | Work in Progress. |
| `run()` | To be implemented. |
| `trade()` | Work in progress. |
|`.emulate_init()`| Work in progress. |  |
|`.emulate_iterate()`| To be implemented. |

### Regarding Visualization

As mentioned in the overview section. We haven't made much concrete achievement — in the sense of having something incorporable to the other two modules of the project — in comparison to our last report. Other than the time issue of midterms, this delay is also due to Mocun (who was originally in charge of visualization), with his richer experience on scraping, had to work with Henry to overcome the alternative structure of WSJ webpage.

---

## Future Plan

Our general goal remains largely unchanged from the first proposal. So we will still (at least) provide a plain text data provider, a stock market trader (obtaining stock market data + backtesting), and a visualizer. As mentioned in pervious report, we will reasonably scale down or up on our implementation regarding the features on model-friendly data manipulation, complexity of visualization, and technical advancement of the demo model.

For now, we plan to incorporate some data manipulation into the future implementation of JSON schema. And we will make a "dummy" model around the data manipulation methods we offered for the pure purpose of demonstrating the capability of the project.

Other then the above mentioned segments — which are mostly tasks related to coding — we understand the maturity and usability of a tool is heavily depended on its provided documentation and manual. Thus, we will allocate time to provide [an user manual like this](https://github.com/choH/half_tael_DQN/blob/master/demo_and_manual/User%20Manual%20for%20trade_interface.py.md) (which one of our group member have previously done for another project) to facility our potential users. As now the `text_obtainer` is almost fully developed, we realized there should be a reader-friendly manual to introduce how to pipeline the obtainer workflow to our potential users.

Please refer to the **Updated Management Plan** section for a more detailed timeline for future plan.

---

## Updated Management Plan


* Week of 11/09/2020:
    * Refine development of text obtainer and virtual trading platform.
    * Test and debug coupling between virtual trading platform and text obtainer.
    * Develop visualizer.
    * Finish development of dummy model.

* Week of 11/16/2020:
    * Finish coupling virtual trading platform with text obtainer and test coupling everything together.
    * Develop visualizer.
    * Paper writing.
    * (Reduced workload due to Paper writing)

* Week of 11/23/2020:
    * Test and debug coupling everything together.
    * Final report writing.
    * Polishing our delivery.

---
## Contribution Acknowledgment



* **Henry ZHONG**
    * Developed WSJ scraper scripts (to support the alternative tag structure) with the help of Mocun. `code`
    * Refactored WSJ scraper scripts. `code`
    * Designed the folder structure of text obtainer. `design`
    * Drafted **Regarding Text Input** section of *Progress Report 2* with Mocun. `report`
    * Wrote **Background** section of *Progress Report 2*. It is mostly similar to what we have in *Progress Report 1* which involves Jiaqi's input. `report`
    * Wrote **Future Plan** and **Updated Management Plan** sections of *Progress Report 2*, however the it is just a reflection of our team discussion.  `report` `management`

* **Jiaqi YU**
    * Researched the implementations of necessary components of stock market trading. `design`
    * Developed virtual trading platform. `code`
    * Drafted **Regarding Trading** section of *Progress Report 2*. `report`
    * Contributed to **Future Plan** and **Updated Management Plan** sections of *Progress Report 2*. `report` `management`


* **Mocun YE**
    * Experimenting basic of of data visualizer. `code`
    * Researched the design of data visualizer with respect to back testing platform. `design`
    * Developed WSJ scraper script (focus on the alternative tag structure) with Henry. `code`
    * Contributed to **Regarding Text Input** section of *Progress Report 2* with Henry. `report`
    * Drafted **Regarding Visualization** section of *Progress Report 2*. `report`
   * Contributed to **Future Plan** and **Updated Management Plan** sections of *Progress Report 2*. `report` `management`